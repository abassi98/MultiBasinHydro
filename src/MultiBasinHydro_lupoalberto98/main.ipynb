{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset, Subset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping \n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# user functions\n",
    "from dataset import CamelDataset\n",
    "from models import Hydro_LSTM_AE\n",
    "from utils import Scale_Data, MetricsCallback, NSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x132b3da90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Camel ...\n",
      "... done.\n",
      "Number of basins: 10\n",
      "Number of points: 7305\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "dates = [\"1989/10/01\", \"2009/09/30\"]\n",
    "camel_dataset = CamelDataset(dates)\n",
    "#dataset.adjust_dates() # adjust dates if necessary\n",
    "camel_dataset.load_data() # load data\n",
    "num_basins = camel_dataset.__len__()\n",
    "seq_len = camel_dataset.seq_len\n",
    "print(\"Number of basins: %d\" %num_basins)\n",
    "print(\"Number of points: %d\" %seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataloader\n",
    "batch_size = 32\n",
    "# split 80/10/10 %\n",
    "\n",
    "num_train_data = int(num_basins * 0.8) \n",
    "num_val_data = int(num_basins * 0.1) \n",
    "num_test_data = num_basins - num_train_data - num_val_data\n",
    "print(\"Train basins: %d\" %num_train_data)\n",
    "print(\"Validation basins: %d\" %num_val_data)\n",
    "print(\"Test basins: %d\" %num_test_data)\n",
    "train_dataset, val_dataset, test_data = random_split(camel_dataset, (num_train_data, num_val_data, num_test_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=num_val_data, num_workers=8, shuffle=False)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=num_test_data, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "loss_fn = NSELoss()\n",
    "# possibly adjust kernel sizes according to seq_len\n",
    "model = Hydro_LSTM_AE(in_channels=(1,8,16), \n",
    "                out_channels=(8,16,32), \n",
    "                kernel_sizes=((6, 1), (4, 1), (4, 1)), \n",
    "                encoded_space_dim=27,\n",
    "                drop_p=0.5,\n",
    "                seq_len=seq_len,\n",
    "                lr = 0.001,\n",
    "                act=nn.LeakyReLU,\n",
    "                loss_fn=loss_fn,\n",
    "                lstm_hidden_units=100,\n",
    "                layers_num=2,\n",
    "                linear=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "# define callbacks\n",
    "metrics_callback = MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define trainer \n",
    "trainer = pl.Trainer(max_epochs=2, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1, check_val_every_n_epoch=10, deterministic=True)\n",
    "trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.plot(- np.array(metrics_callback.train_loss_log), label=\"train NSE\")\n",
    "ax.plot(- np.array(metrics_callback.val_loss_log), label=\"validation NSE\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"NSE\")\n",
    "ax.legend()\n",
    "#fig.savefig(\"NSE_epochs.png\")\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
