{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cca0db3-4ef7-49c4-a54e-dbdf5be12fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-lightning\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset, Subset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping \n",
    "from torchvision import transforms, datasets\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "# user functions\n",
    "from dataset import CamelDataset\n",
    "from models import Hydro_LSTM_AE, Hydro_LSTM\n",
    "from utils import Scale_Data, MetricsCallback, NSELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e15da3-822a-4f5e-be67-baaa7c4fac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x127f3fa30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################\n",
    "# set seed\n",
    "##########################################################\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad992be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# mount drive\n",
    "##########################################################\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bef62",
   "metadata": {},
   "source": [
    "### Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b1367c-b72c-456b-9202-f023a5707db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Camel ...\n",
      "... done.\n",
      "Number of basins: 10\n",
      "Sequence length: 10957\n"
     ]
    }
   ],
   "source": [
    "##########################################################  \n",
    "# dataset and dataloaders\n",
    "##########################################################\n",
    "# Dataset\n",
    "#dates = [\"1989/10/01\", \"2009/09/30\"] \n",
    "dates = [\"1980/10/01\", \"2010/09/30\"] # interval dates to pick\n",
    "force_attributes = [\"prcp(mm/day)\", \"srad(W/m2)\", \"tmin(C)\", \"tmax(C)\", \"vp(Pa)\"] # force attributes to use\n",
    "camel_dataset = CamelDataset(dates, force_attributes, data_path=\"gdrive/MyDrive/basin_dataset_public_v1p2\") # use dataset on google drive\n",
    "#dataset.adjust_dates() # adjust dates if necessary\n",
    "camel_dataset.load_data() # load data\n",
    "num_basins = camel_dataset.__len__()\n",
    "seq_len = camel_dataset.seq_len\n",
    "print(\"Number of basins: %d\" %num_basins)\n",
    "print(\"Sequence length: %d\" %seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ce76123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cpus: 8\n",
      "Num of gpus: 0\n",
      "Training device: cpu\n",
      "Number of workers: 0\n",
      "Train basins: 8\n",
      "Validation basins: 2\n"
     ]
    }
   ],
   "source": [
    " ### Set proper device and train\n",
    "# check cpus and gpus available\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(\"Num of cpus: %d\"%num_cpus)\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Num of gpus: %d\"%num_gpus)\n",
    "    \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "\n",
    "### Dataloader\n",
    "batch_size = 32\n",
    "# split 80/10/10\n",
    "num_workers = 0\n",
    "print(\"Number of workers: %d\"%num_workers)\n",
    "\n",
    "num_train_data = int(num_basins * 0.8) \n",
    "num_val_data = num_basins - num_train_data\n",
    "#num_test_data = num_basins - num_train_data - num_val_data\n",
    "print(\"Train basins: %d\" %num_train_data)\n",
    "print(\"Validation basins: %d\" %num_val_data)\n",
    "#print(\"Test basins: %d\" %num_test_data)\n",
    "    \n",
    "train_dataset, val_dataset = random_split(camel_dataset, (num_train_data, num_val_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=num_val_data, num_workers=num_workers, shuffle=False)\n",
    "#test_dataloader = DataLoader(val_dataset, batch_size=num_test_data, num_workers=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb46f29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc234762",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# define the model\n",
    "loss_fn = NSELoss()\n",
    "# possibly adjust kernel sizes according to seq_len\n",
    "model = Hydro_LSTM_AE(in_channels=(1,8,16), \n",
    "                    out_channels=(8,16,32), \n",
    "                    kernel_sizes=(6,3,5), \n",
    "                    encoded_space_dim=27,\n",
    "                    drop_p=0.5,\n",
    "                    seq_len=seq_len,\n",
    "                    lr = 1e-4,\n",
    "                    act=nn.LeakyReLU,\n",
    "                    loss_fn=loss_fn,\n",
    "                    lstm_hidden_units=256,\n",
    "                    layers_num=2,\n",
    "                    linear=512,\n",
    "                    num_force_attributes = len(force_attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# training \n",
    "##########################################################\n",
    "\n",
    "    \n",
    "# define callbacks\n",
    "metrics_callback = MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=100,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=\"gdrive/MyDrive/checkpoints/lstm-ae/\",\n",
    "        filename=\"hydro-lstm-ae-{epoch:02d}\",\n",
    "    )\n",
    "\n",
    "    \n",
    "# define trainer \n",
    "trainer = pl.Trainer(max_epochs=3000, callbacks=[checkpoint_callback], accelerator=str(device), check_val_every_n_epoch=10, logger=False)\n",
    "\n",
    "# train model   \n",
    "trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# training from best model\n",
    "##########################################################\n",
    "\n",
    "\n",
    "# train the best model\n",
    "id_best = str(509)\n",
    "ckpt_path = \"gdrive/MyDrive/checkpoints/lstm-ae/hydro-lstm-ae-epoch=\"+id_best+\".ckpt\"\n",
    "# define the model\n",
    "loss_fn = NSELoss()\n",
    "# upload best model and set new learning rate\n",
    "model = Hydro_LSTM_AE.load_from_checkpoint(ckpt_path, lr=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "metrics_callback = MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=100,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=\"gdrive/MyDrive/checkpoints/lstm-ae/\",\n",
    "        filename=\"hydro-lstm-ae-{epoch:02d}\",\n",
    "    )\n",
    "\n",
    "    \n",
    "# define trainer \n",
    "trainer = pl.Trainer(max_epochs=3000, callbacks=[checkpoint_callback], accelerator=str(device), check_val_every_n_epoch=10, logger=False)\n",
    "\n",
    "# train model   \n",
    "trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0c5a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSTM benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19ee0322-bb22-48f0-8d13-aa64576af557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM initialized\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# define the model\n",
    "loss_fn = NSELoss()\n",
    "# possibly adjust kernel sizes according to seq_len\n",
    "model_lstm = Hydro_LSTM(lstm_hidden_units = 256, \n",
    "                 bidirectional = False,\n",
    "                 layers_num = 2,\n",
    "                 act = nn.LeakyReLU, \n",
    "                 loss_fn = loss_fn,\n",
    "                 drop_p = 0.5, \n",
    "                 seq_len = seq_len,\n",
    "                 lr = 1e-4,\n",
    "                 weight_decay = 0.0,\n",
    "                 num_force_attributes = len(force_attributes),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1af5b62e-046f-4bad-b859-04476bdaf556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | sigmoid | Sigmoid | 0     \n",
      "1 | loss_fn | NSELoss | 0     \n",
      "2 | lstm    | LSTM    | 795 K \n",
      "3 | out     | Linear  | 257   \n",
      "------------------------------------\n",
      "795 K     Trainable params\n",
      "0         Non-trainable params\n",
      "795 K     Total params\n",
      "3.184     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a343f7af1d48e6b33cf9dde283882a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6273c7ba74480aa950f30a66d6f528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fd2164ce454885b2394aa228661ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:727: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# training \n",
    "##########################################################\n",
    "\n",
    "# define callbacks\n",
    "metrics_callback = MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=100,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=\"../../checkpoints/lstm/\",\n",
    "        filename=\"hydro-lstm-{epoch:02d}\",\n",
    "    )\n",
    "\n",
    "    \n",
    "# define trainer \n",
    "trainer = pl.Trainer(max_epochs=3000, callbacks=[checkpoint_callback], accelerator=str(device), check_val_every_n_epoch=10, logger=False)\n",
    "\n",
    "# train model   \n",
    "trainer.fit(model=model_lstm, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51586b4-cc98-4eb9-ae42-2bcd8c74856a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8e32e4e88e316d03ef1b150b22c8f1da2186227352b51db230550a229c89091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
