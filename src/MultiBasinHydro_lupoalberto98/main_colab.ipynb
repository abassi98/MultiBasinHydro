{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cca0db3-4ef7-49c4-a54e-dbdf5be12fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-lightning\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset, Subset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping \n",
    "from torchvision import transforms, datasets\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "# user functions\n",
    "from dataset import CamelDataset\n",
    "from models import Hydro_LSTM_AE\n",
    "from utils import Scale_Data, MetricsCallback, NSELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e15da3-822a-4f5e-be67-baaa7c4fac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136101a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################\n",
    "# set seed\n",
    "##########################################################\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad992be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# mount drive\n",
    "##########################################################\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b1367c-b72c-456b-9202-f023a5707db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Camel ...\n",
      "... done.\n",
      "Number of basins: 562\n",
      "Sequence length: 10957\n"
     ]
    }
   ],
   "source": [
    "##########################################################  \n",
    "# dataset and dataloaders\n",
    "##########################################################\n",
    "# Dataset\n",
    "#dates = [\"1989/10/01\", \"2009/09/30\"] \n",
    "dates = [\"1980/10/01\", \"2010/09/30\"] # interval dates to pick\n",
    "force_attributes = [\"prcp(mm/day)\", \"srad(W/m2)\", \"tmin(C)\", \"tmax(C)\", \"vp(Pa)\"] # force attributes to use\n",
    "camel_dataset = CamelDataset(dates, force_attributes, data_path=\"../../basin_dataset_public_v1p2\") # use dataset on google drive\n",
    "#dataset.adjust_dates() # adjust dates if necessary\n",
    "camel_dataset.load_data() # load data\n",
    "num_basins = camel_dataset.__len__()\n",
    "seq_len = camel_dataset.seq_len\n",
    "print(\"Number of basins: %d\" %num_basins)\n",
    "print(\"Sequence length: %d\" %seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce76123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cpus: 8\n",
      "Num of gpus: 0\n",
      "Training device: cpu\n",
      "Number of workers: 0\n",
      "Train basins: 449\n",
      "Validation basins: 113\n"
     ]
    }
   ],
   "source": [
    " ### Set proper device and train\n",
    "# check cpus and gpus available\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(\"Num of cpus: %d\"%num_cpus)\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Num of gpus: %d\"%num_gpus)\n",
    "    \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "\n",
    "### Dataloader\n",
    "batch_size = 32\n",
    "# split 80/10/10\n",
    "num_workers = 0\n",
    "print(\"Number of workers: %d\"%num_workers)\n",
    "\n",
    "num_train_data = int(num_basins * 0.8) \n",
    "num_val_data = num_basins - num_train_data\n",
    "#num_test_data = num_basins - num_train_data - num_val_data\n",
    "print(\"Train basins: %d\" %num_train_data)\n",
    "print(\"Validation basins: %d\" %num_val_data)\n",
    "#print(\"Test basins: %d\" %num_test_data)\n",
    "    \n",
    "train_dataset, val_dataset = random_split(camel_dataset, (num_train_data, num_val_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=num_val_data, num_workers=num_workers, shuffle=False)\n",
    "#test_dataloader = DataLoader(val_dataset, batch_size=num_test_data, num_workers=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc234762",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# define the model\n",
    "loss_fn = NSELoss()\n",
    "# possibly adjust kernel sizes according to seq_len\n",
    "model = Hydro_LSTM_AE(in_channels=(1,8,16), \n",
    "                    out_channels=(8,16,32), \n",
    "                    kernel_sizes=(6,3,5), \n",
    "                    encoded_space_dim=27,\n",
    "                    drop_p=0.5,\n",
    "                    seq_len=seq_len,\n",
    "                    lr = 1e-4,\n",
    "                    act=nn.LeakyReLU,\n",
    "                    loss_fn=loss_fn,\n",
    "                    lstm_hidden_units=256,\n",
    "                    layers_num=2,\n",
    "                    linear=512,\n",
    "                    num_force_attributes = len(force_attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# training \n",
    "##########################################################\n",
    "\n",
    "    \n",
    "# define callbacks\n",
    "metrics_callback = MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=100,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=\"gdrive/MyDrive/checkpoints/lstm-ae/\",\n",
    "        filename=\"hydro-lstm-ae-{epoch:02d}\",\n",
    "    )\n",
    "\n",
    "    \n",
    "# define trainer \n",
    "trainer = pl.Trainer(max_epochs=3000, callbacks=[metrics_callback, checkpoint_callback], accelerator=str(device), check_val_every_n_epoch=10, logger=False)\n",
    "\n",
    "# train model   \n",
    "trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f7d77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional LSTM Autoencoder initialized\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# training from best model\n",
    "##########################################################\n",
    "\n",
    "\n",
    "# train the best model\n",
    "id_best = str(509)\n",
    "ckpt_path = \"../../checkpoints/lstm-ae/hydro-lstm-ae-epoch=\"+id_best+\".ckpt\"\n",
    "# define the model\n",
    "loss_fn = NSELoss()\n",
    "# upload best model and set new learning rate\n",
    "model = Hydro_LSTM_AE.load_from_checkpoint(ckpt_path)\n",
    "model.lr = 1e-5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type        | Params\n",
      "----------------------------------------\n",
      "0 | sigmoid | Sigmoid     | 0     \n",
      "1 | loss_fn | MSELoss     | 0     \n",
      "2 | encoder | ConvEncoder | 2.8 M \n",
      "3 | lstm    | LSTM        | 823 K \n",
      "4 | out     | Linear      | 257   \n",
      "----------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.510    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e201b75b14c47ecbd837e27c7a78bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# define callbacks\n",
    "metrics_callback = MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 10, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=100,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=\"gdrive/MyDrive/checkpoints/lstm-ae/\",\n",
    "        filename=\"hydro-lstm-ae-{epoch:02d}\",\n",
    "    )\n",
    "\n",
    "    \n",
    "# define trainer \n",
    "trainer = pl.Trainer(max_epochs=3000, callbacks=[metrics_callback, checkpoint_callback], accelerator=str(device), check_val_every_n_epoch=10, logger=False)\n",
    "\n",
    "# train model   \n",
    "trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352208d-a76d-4d6a-b753-7ceed5cc9e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8e32e4e88e316d03ef1b150b22c8f1da2186227352b51db230550a229c89091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
